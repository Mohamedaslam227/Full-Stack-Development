{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 10\n",
      "Class names: ['SUV', 'bus', 'family sedan', 'fire engine', 'heavy truck', 'jeep', 'minibus', 'racing car', 'taxi', 'truck']\n",
      "Number of images: 1400\n",
      "Epoch 1/10, Training Loss: 2.3361504077911377, Validation Loss: 2.37186484677451, Validation Accuracy: 0.1\n",
      "Epoch 2/10, Training Loss: 2.4194839000701904, Validation Loss: 2.37186484677451, Validation Accuracy: 0.1\n",
      "Epoch 3/10, Training Loss: 2.377817153930664, Validation Loss: 2.37186484677451, Validation Accuracy: 0.1\n",
      "Epoch 4/10, Training Loss: 2.4194839000701904, Validation Loss: 2.37186484677451, Validation Accuracy: 0.1\n",
      "Epoch 5/10, Training Loss: 2.3361504077911377, Validation Loss: 2.37186484677451, Validation Accuracy: 0.1\n",
      "Epoch 6/10, Training Loss: 2.377817153930664, Validation Loss: 2.37186484677451, Validation Accuracy: 0.1\n",
      "Epoch 7/10, Training Loss: 2.2944839000701904, Validation Loss: 2.37186484677451, Validation Accuracy: 0.1\n",
      "Epoch 8/10, Training Loss: 2.3361504077911377, Validation Loss: 2.37186484677451, Validation Accuracy: 0.1\n",
      "Epoch 9/10, Training Loss: 2.2944839000701904, Validation Loss: 2.37186484677451, Validation Accuracy: 0.1\n",
      "Epoch 10/10, Training Loss: 2.4194839000701904, Validation Loss: 2.37186484677451, Validation Accuracy: 0.1\n",
      "Test predictions saved at test_predictions.npy.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# EDA of the dataset\n",
    "def eda_vehicle_dataset(dataset):\n",
    "    print(f\"Number of classes: {len(dataset.classes)}\")\n",
    "    print(f\"Class names: {dataset.classes}\")\n",
    "    print(f\"Number of images: {len(dataset)}\")\n",
    "\n",
    "# Custom Dataset Class for Test Set (No subfolders)\n",
    "class CustomTestDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(root_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.images[idx])\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "# Replace with your actual dataset paths\n",
    "train_dataset_path = r'E:\\Tim\\sem 6\\DL lab\\ex2\\q3\\data\\train'\n",
    "val_dataset_path = r'E:\\Tim\\sem 6\\DL lab\\ex2\\q3\\data\\val'\n",
    "test_dataset_path = r'E:\\Tim\\sem 6\\DL lab\\ex2\\q3\\data\\test'\n",
    "\n",
    "# Define data transforms\n",
    "vehicle_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load and explore the datasets\n",
    "train_dataset = ImageFolder(root=train_dataset_path, transform=vehicle_transform)\n",
    "val_dataset = ImageFolder(root=val_dataset_path, transform=vehicle_transform)\n",
    "test_dataset = CustomTestDataset(root_dir=test_dataset_path, transform=vehicle_transform)\n",
    "\n",
    "eda_vehicle_dataset(train_dataset)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define MLP model for classification with more hidden layers\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(hidden_sizes)):\n",
    "            if i == 0:\n",
    "                layers.append(nn.Linear(input_size, hidden_sizes[i]))\n",
    "            else:\n",
    "                layers.append(nn.Linear(hidden_sizes[i-1], hidden_sizes[i]))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(hidden_sizes[-1], output_size))\n",
    "        layers.append(nn.Softmax(dim=1))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Instantiate the model, loss function, and optimizer\n",
    "input_size = 224 * 224 * 3  # Assuming RGB images\n",
    "hidden_sizes = [128, 64]  # Add more hidden layers as needed\n",
    "output_size = len(train_dataset.classes)\n",
    "\n",
    "vehicle_model = MLPClassifier(input_size, hidden_sizes, output_size)\n",
    "criterion_vehicle = nn.CrossEntropyLoss()\n",
    "optimizer_vehicle = optim.Adam(vehicle_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "epochs_vehicle = 10\n",
    "for epoch in range(epochs_vehicle):\n",
    "    vehicle_model.train()\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs = inputs.view(inputs.size(0), -1)  # Flatten the input\n",
    "        optimizer_vehicle.zero_grad()\n",
    "        outputs = vehicle_model(inputs)\n",
    "        loss = criterion_vehicle(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_vehicle.step()\n",
    "\n",
    "    # Validation\n",
    "    vehicle_model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels in val_dataloader:\n",
    "            val_inputs = val_inputs.view(val_inputs.size(0), -1)\n",
    "            val_outputs = vehicle_model(val_inputs)\n",
    "            val_loss += criterion_vehicle(val_outputs, val_labels).item()\n",
    "            _, predicted = torch.max(val_outputs, 1)\n",
    "            total += val_labels.size(0)\n",
    "            correct += (predicted == val_labels).sum().item()\n",
    "\n",
    "    average_val_loss = val_loss / len(val_dataloader)\n",
    "    accuracy = correct / total\n",
    "    print(f'Epoch {epoch + 1}/{epochs_vehicle}, Training Loss: {loss.item()}, Validation Loss: {average_val_loss}, Validation Accuracy: {accuracy}')\n",
    "\n",
    "# Testing the model\n",
    "vehicle_model.eval()\n",
    "test_predictions = []\n",
    "with torch.no_grad():\n",
    "    for test_inputs in test_dataloader:\n",
    "        test_inputs = test_inputs.view(test_inputs.size(0), -1)\n",
    "        test_outputs = vehicle_model(test_inputs)\n",
    "        _, test_predicted = torch.max(test_outputs, 1)\n",
    "        test_predictions.extend(test_predicted.cpu().numpy())\n",
    "\n",
    "# Save the test predictions if needed\n",
    "test_predictions_path = 'test_predictions.npy'\n",
    "np.save(test_predictions_path, np.array(test_predictions))\n",
    "print(f\"Test predictions saved at {test_predictions_path}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
